#扩展性
- 以 HDFS 为代表的分布式存储框架，通过把数据切分成固定大小的 block，再搭配记录 block 位置的元数据，就解决了数据存储扩展性的问题。
- 以 MapReduce 为代表的分布式计算框架，通过把计算逻辑切分成一个个 Mapper 和 Reducer，就解决了数据计算扩展性的问题。

##对于扩展性，我们需要关注：
1. parititioning 方式，即数据在逻辑上怎么切分
2. localization 方式，即数据在物理上怎么分布
3. rebalance 方式，即在节点数变化后，数据在物理上怎么重新分布

###文件数据，文件系统上任意格式的文件
- parititioning: 以固定大小的block来切分数据，再搭配一个元数据，记录文件和 block 的对应关系，以及 block 和机器的对应关系。
- localization: 随机分布在各个机器节点。
- rebalance: 首先复制数据，然后修改元数据。

###key-value 数据，带主键的数据
- parititioning: 以key做partitioning的操作，例如key range划分、hash key划分等
    - key range可以范围查询
    - hash key可以解决数据倾斜
    - 一般做法是对 key 做 hash ，然后继续按 range 来做切分
    - 还有一个方法是组合主键k1_k2，k1用作hash，k2满足范围查询(Cassandra的实现)
- localization: 
    1. hash mod N  来确定数据应该放到哪个分区，其中 N 为节点数
    2. 固定数量的 partition
    3. 动态数量的 partition
- rebalance: 通过split和merge来rebalance

###文档数据，类似 json 格式的数据，和 key-value 的区别是没有业务意义上的主键
- parititioning: 文档数据其实是 {doc_id: doc} 的 key-value 结构，所以可以采用key-value的分区方式
- localization: 可以通过二级索引来查询

